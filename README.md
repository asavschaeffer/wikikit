# ðŸŒŸ WikiKit: Transform LLM Conversations into Surgical Development Blueprints

> A systematic approach to capturing conversation intelligence and transforming it into implementation-ready documentation

---

## ðŸŽ¯ The Problem We Solve

You've just spent 3 hours brainstorming with an LLM. You've explored architectures, discussed trade-offs, and made key technical decisions. But now you're left with:

* ðŸ’¬ Hours of rich discussion â€” hard to reference later
* ðŸ” Key decisions buried in dozens of scattered replies
* ðŸ“‹ No structured documentation to build from
* ðŸ”„ Critical context lost when the conversation ends

**WikiKit solves this** by providing extraction-focused prompts that transform conversation history into comprehensive, implementation-ready documentation.

---

## ðŸ§  Core Philosophy: Extraction Over Generation

WikiKit prompts are **information organizers**, not idea generators. They systematically extract and structure the intelligence already present in your conversations, creating documentation so detailed that development becomes surgical:

> Instead of:

```txt
"Build me a user authentication system"
```

> You can say:

```txt
"Implement the JWT-based authentication flow specified in ADR-001,
 using the bcrypt parameters from Security Architecture section 3.2"
```

---

## ðŸ“¦ What's Inside

### ðŸŽ¯ Lite Prompts (30-50 lines)

Fast extraction when context windows are tight:

* `technical-decisions-quick.yaml` â€“ Key technology choices
* `feature-list-quick.yaml` â€“ Core functionality summary
* `project-summary-quick.yaml` â€“ Everything in one shot
* *Token-efficient for laggy conversations*

### ðŸ“š Full Prompts (300-500 lines)

Comprehensive documentation with FAANG-level rigor:

* `technical-feasibility-adr.yaml` â€“ Complete ADRs with risk analysis
* `functional-requirements.yaml` â€“ IEEE 830 standard requirements
* `high-level-design.yaml` â€“ System architecture with C4 models
* *Use when you need production-ready documentation*

### ðŸ”§ Shared Components

Reusable patterns ensuring consistency:

* `decision-markers.yaml` â€“ Standardized markers (âœ… VERIFIED, âš ï¸ RISK, etc.)
* `extraction-patterns.yaml` â€“ Common extraction targets
* `prompt-wizardry.yaml` â€“ Quality activation techniques

### ðŸ“‘ Document Types Supported

**Planning Phase**
â†’ Product Research & Discovery
â†’ Project Vision
â†’ Elevator Pitch
â†’ Technical Feasibility & ADRs

**Requirements**
â†’ Functional Requirements
â†’ Non-Functional Requirements
â†’ User Flows & Mockups

**Architecture**
â†’ High-Level Design
â†’ Low-Level Design
â†’ API Specifications
â†’ Database Design
â†’ Security Architecture

**Implementation**
â†’ Development Roadmap
â†’ Testing Strategy
â†’ Deployment Infrastructure
â†’ Monitoring & Observability

**Business**
â†’ Business Strategy
â†’ Go-to-Market Strategy

---

## ðŸŽ­ Prompt Engineering Techniques

### Pattern Activation

Our prompts use specific phrases to activate high-quality patterns in LLM training data:

* "Principal Software Architect at Netflix/Google/Amazon scale"
* "Following IEEE 830 standards"
* "Production-ready implementation"
* "EXHAUST YOUR FULL PROCESSING CAPACITY"

### Cognitive Framing

* ðŸ§  **Role Precision**: Not just "engineer" but "senior backend engineer specializing in distributed systems"
* ðŸ—ï¸ **Quality Context**: "Building for millions of users" vs "building an app"
* ðŸ” **Systematic Thinking**: Step-by-step protocols prevent shortcuts

### Evidence Grounding

Every prompt enforces evidence traceability:

```yaml
confidence_markers:
  verified: "âœ… VERIFIED: Explicitly stated in conversation"
  derived: "ðŸ“Š DERIVED: Logically inferred from [specific evidence]"
  gap: "âŒ DATA GAP: Critical information not discussed"
```

---

## ðŸ” Usage Patterns

### ðŸ“ˆ Progressive Enhancement

```txt
ðŸ’¡ â†’ âœ‚ï¸ â†’ ðŸ§ª â†’ ðŸ—ï¸
Lite Prompt â†’ Gap Review â†’ Targeted Prompts â†’ Final Docs
```

### ðŸ“¤ Post-Conversation Extraction

```txt
ðŸ—£ï¸ â†’ â¹ï¸ â†’ ðŸ“¦ â†’ ðŸ§±
Natural Chat â†’ Stop â†’ Load Prompts â†’ Doc Suite
```

### ðŸ” Iterative Refinement

```txt
ðŸ“¦ â†’ ðŸ” â†’ âœï¸ â†’ ðŸ“¦
Extract â†’ Review â†’ Clarify â†’ Re-extract
```

---

## ðŸ—‚ï¸ Directory Structure

```txt
wikikit/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ full/          # Comprehensive prompts (300-500 lines)
â”‚   â”œâ”€â”€ lite/          # Quick extraction (30-50 lines)
â”‚   â”œâ”€â”€ shared/        # Reusable components
â”‚   â””â”€â”€ workflows/     # Multi-prompt sequences
â”œâ”€â”€ wiki-scaffolds/    # Example outputs
â”œâ”€â”€ tools/             # Automation utilities
â””â”€â”€ docs/              # Guides and philosophy
```

---

## âš ï¸ Important Considerations

### Context Window Management

* Full prompts consume 1-3k tokens each
* Use lite prompts when conversation is already long
* Consider starting fresh conversations for each major document

### Quality vs Speed Trade-offs

* **Lite prompts**: Quick insights, may miss nuance
* **Full prompts**: Complete extraction, slower processing
* Choose based on your immediate needs

### Extraction Fidelity

* WikiKit extracts what was discussed, not what should have been
* Gaps in conversation become gaps in documentation
* Use "DATA GAP" markers to identify what needs discussion

---

## ðŸ”¬ Advanced Techniques

### Intermediate Extraction

Some prompts support phased extraction:

```yaml
extraction_phases:
  - raw_extraction: "List all mentioned items"
  - organization: "Group into categories"  
  - synthesis: "Generate final document"
```

### Prompt Chaining

Output from one prompt can seed another:

```bash
# 1. Extract requirements
# 2. Feed requirements into technical feasibility
# 3. Use feasibility to guide architecture design
```

### Dynamic Adaptation

Prompts adapt to your tech stack:

* Mention "using React" â†’ Examples use React
* Discuss "PostgreSQL" â†’ SQL examples throughout
* Reference "microservices" â†’ Distributed patterns

---

## ðŸ¤ Contributing

WikiKit improves through real usage. We welcome:

### Prompt Improvements

* Better extraction patterns
* Clearer decision markers
* More efficient token usage

### New Document Types

* Specialized domains (mobile, ML, blockchain)
* Industry-specific compliance docs
* Team process documentation

### Usage Examples

* Successful extraction patterns
* Multi-prompt workflows
* Integration with development tools

---

## ðŸ“ˆ Roadmap

### Near Term
- [ ] Non-Functional Requirements prompt
- [ ] User Flows & Mockups prompt
- [ ] Development Roadmap prompt
- [ ] Testing Strategy prompt
- [ ] Elevator Pitch prompt

### Medium Term
- [ ] Complete remaining full prompts (Database Design, Security Architecture, etc.)
- [ ] Create lite versions for all document types
- [ ] Wiki scaffold templates for each document type
- [ ] Prompt selector tool ("Which prompt do I need?")

### Long Term
- [ ] Shared components library
- [ ] Workflow automation tools
- [ ] CLI tool for prompt injection
- [ ] VSCode/Cursor extension
- [ ] Multi-conversation synthesis

---

## ðŸ“„ License

MIT License â€” Build better software through better documentation.

---

**Status**: Work in Progress | **Next Focus**: Improve LLD prompt to avoid overengineering

>*"The quality of your documentation determines the precision of your development."*
>
> <div align="center">â€” Claude 4 Sonnet</div>
